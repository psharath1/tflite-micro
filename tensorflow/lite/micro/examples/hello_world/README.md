<!-- mdformat off(b/169948621#comment2) -->

# Hello World Example

This example is designed to demonstrate the absolute basics of using [TensorFlow
Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers).
It includes the full end-to-end workflow of training a model, converting it for
use with TensorFlow Lite for Microcontrollers for running inference on a
microcontroller.

## Table of contents

-   [Run the evaluate.py script on a development machine](#run-the-evaluate-script-on-a-development-machine)
-   [Run the tests on a development machine](#run-the-tests-on-a-development-machine)
-   [Train your own model](#train-your-own-model)

## Run the evaluate.py script on a development machine
The evaluate.py script runs the hello_world.tflite model with x_values in the 
range of [0, 2*PI]. The script plots a diagram of the predicted value of sinwave
using TFLM interpreter and compare that prediction with the actual value
generated by the numpy lib.
```bash
bazel build :evaluate
bazel run :evaluate
bazel run :evaluate -- --use_tflite
```
![TFLM hello_world sinwave prediction VS actual values](images/hello_world_tflm.png)   ![TFLM hello_world sinwave prediction VS actual values](images/hello_world_tflite.png)

## Run the evaluate_test.py script on a development machine
These tests verify the input/output as well as the prediction of the
hello_world.tflite model. There is a test to also verify the correctness of
the model by running both TFLM and TFlite interpreter and then comparing the
prediction from both interpreters.
```bash
bazel build :evaluate_test
bazel run :evaluate_test
```

## Run the tests on a development machine

Run the cc test using bazel
```bash
bazel run tensorflow/lite/micro/examples/hello_world:evaluate_cc_test
```
And to run it using make 
```bash
make -f tensorflow/lite/micro/tools/make/Makefile test_evaluate_cc_test
```

The source for the test is [evaluate_test.cc](evaluate_test.cc).
It's a fairly small amount of code that creates an interpreter, gets a handle to
a model that's been compiled into the program, and then invokes the interpreter
with the model and sample inputs.

## Train your own model

So far you have used an existing trained model to run inference on
microcontrollers. If you wish to train your own model, follow the instructions
given in the [train/](train/) directory.

